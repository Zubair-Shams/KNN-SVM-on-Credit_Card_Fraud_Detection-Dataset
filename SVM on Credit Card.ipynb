{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#for time count we use belwo library\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yi * (W) power (t) Xi  + bi >= 1\n",
    "\n",
    "\n",
    "(w*, b*) = ( ||w|| /2 ) + Ci + Sumof Zeta : c=how many errors, Zeta = value of the error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data\n",
    "\n",
    "Set index_col=0 to use the first column as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd58f110>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_Class=pd.value_counts(df[\"Class\"], sort= True)\n",
    "count_Class.plot(kind= 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of fraudulent transactions( Class 1) are:  492\n",
      "The number of normal transactions( Class 0) are:  284315\n",
      "Class 0 percentage =  99.82725143693798\n",
      "Class 1 percentage =  0.1727485630620034\n"
     ]
    }
   ],
   "source": [
    "No_of_frauds= len(df[df[\"Class\"]==1])\n",
    "No_of_normals = len(df[df[\"Class\"]==0])\n",
    "print(\"The number of fraudulent transactions( Class 1) are: \", No_of_frauds)\n",
    "print(\"The number of normal transactions( Class 0) are: \", No_of_normals)\n",
    "total= No_of_frauds + No_of_normals\n",
    "Fraud_percent= (No_of_frauds / total)*100\n",
    "Normal_percent= (No_of_normals / total)*100\n",
    "print(\"Class 0 percentage = \", Normal_percent)\n",
    "print(\"Class 1 percentage = \", Fraud_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8829017"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size  //"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(df.drop('Class',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler(copy=True, with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = scaler.transform(df.drop('Class',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089611</td>\n",
       "      <td>-0.307377</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-1.378675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680975</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>-1.262503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269855</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529939</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0 -1.996583 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068   \n",
       "1 -1.996583  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820   \n",
       "2 -1.996562 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454   \n",
       "3 -1.996562 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150   \n",
       "4 -1.996541 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0  0.193679  0.082637  0.331128  ...  0.326118 -0.024923  0.382854 -0.176911   \n",
       "1 -0.063700  0.071253 -0.232494  ... -0.089611 -0.307377 -0.880077  0.162201   \n",
       "2  0.639776  0.207373 -1.378675  ...  0.680975  0.337632  1.063358  1.456320   \n",
       "3  0.192071  0.316018 -1.262503  ... -0.269855 -0.147443  0.007267 -0.304777   \n",
       "4  0.479302 -0.226510  0.744326  ...  0.529939 -0.012839  1.100011 -0.220123   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  \n",
       "0  0.110507  0.246585 -0.392170  0.330892 -0.063781  0.244964  \n",
       "1 -0.561131  0.320694  0.261069 -0.022256  0.044608 -0.342475  \n",
       "2 -1.138092 -0.628537 -0.288447 -0.137137 -0.181021  1.160686  \n",
       "3 -1.941027  1.241904 -0.460217  0.155396  0.186189  0.140534  \n",
       "4  0.233250 -0.395202  1.041611  0.543620  0.651816 -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,df['Class'],\n",
    "                                                    test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting SVM to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of Training the Algorithm in second 6518.425388813019\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()  \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print('Time of Training the Algorithm in second',end - start)  #108.6333  mints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Test set results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.182732105255127\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.9994733330992591\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.85      0.84      0.85       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.93      0.92      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy of he model\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score :', accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of Training the Algorithm in second 403.6673035621643\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()  \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print('Time of Training the Algorithm in second',end - start)  #7min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of Training the Algorithm in second 16.22396230697632\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print('Time of Training the Algorithm in second',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.999403110845827\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.95      0.69      0.80       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.84      0.90     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy of he model\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score :', accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\n\\n',classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Poly Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of Training the Algorithm in second 380.45576190948486\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()  \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print('Time of Training the Algorithm in second',end - start)  //5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of Training the Algorithm in second 16.10900902748108\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print('Time of Training the Algorithm in second',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.999403110845827\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.95      0.69      0.80       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.84      0.90     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy of he model\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy Score :', accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\n\\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Xubair\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy in %:  0.9992927505953544\n",
      "The standard deviation in %  0.00012778734633313784\n",
      "The accuracy of our model in % is betweeen 99.91649632490213 and 99.94205379416876\n"
     ]
    }
   ],
   "source": [
    "#Applying 10 fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X=X_train, y = y_train.ravel(), cv = 10)\n",
    "\n",
    "mean_accuracy= accuracies.mean()*100\n",
    "\n",
    "std_accuracy= accuracies.std()*100\n",
    "\n",
    "print(\"The mean accuracy in %: \", accuracies.mean())\n",
    "print(\"The standard deviation in % \", accuracies.std())\n",
    "print(\"The accuracy of our model in % is betweeen {} and {}\".format(mean_accuracy-std_accuracy, mean_accuracy+std_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
